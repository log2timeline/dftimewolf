# -*- coding: utf-8 -*-
"""Processes a directory of artifacts with Turbinia."""

import os
import tempfile

from typing import Optional, TYPE_CHECKING

from turbinia import TurbiniaException, evidence
from turbinia import config as turbinia_config

from dftimewolf.lib import module
from dftimewolf.lib.containers import containers
from dftimewolf.lib.modules import manager as modules_manager
from dftimewolf.lib.processors.turbinia_base import TurbiniaProcessorBase

if TYPE_CHECKING:
  from dftimewolf.lib import state

# pylint: disable=no-member

class TurbiniaArtifactProcessor(TurbiniaProcessorBase, module.ThreadAwareModule):
  """Processes Exported GRR Artifacts with Turbinia.

  Attributes:
    directory_path (str): Name of the directory to process.
  """

  def __init__(self,
               state: "state.DFTimewolfState",
               name: Optional[str]=None,
               critical: bool=False) -> None:
    """Initializes a Turbinia Artifacts disks processor.

    Args:
      state (DFTimewolfState): recipe state.
      name (Optional[str]): The module's runtime name.
      critical (Optional[bool]): True if the module is critical, which causes
          the entire recipe to fail if the module encounters an error.
    """
    super(TurbiniaArtifactProcessor, self).__init__(
        state, name=name, critical=critical)
    self.directory_path = ''

  # pylint: disable=arguments-differ
  def SetUp(self,
            turbinia_config_file: str,
            project: str,
            turbinia_zone: str,
            directory_path: str,
            sketch_id: int,
            run_all_jobs: bool) -> None:
    """Sets up the object attributes.

    Args:
      turbinia_config_file (str): Full path to the Turbinia config file to use.
      project (str): name of the GCP project containing the disk to process.
      turbinia_zone (str): GCP zone in which the Turbinia server is running.
      directory_path (str): Name of the directory to process.
      sketch_id (int): The Timesketch sketch ID.
      run_all_jobs (bool): Whether to run all jobs instead of a faster subset.
    """
    self.turbinia_config_file = turbinia_config_file
    self.directory_path = directory_path
    if not self.directory_path:
      self.directory_path = tempfile.mkdtemp(prefix='turbinia-results')
      self.logger.success('Turbinia results will be dumped to {0:s}'.format(
          self.directory_path))
    try:
      self.TurbiniaSetUp(project, turbinia_zone, sketch_id, run_all_jobs)
    except TurbiniaException as exception:
      self.ModuleError(str(exception), critical=True)
      return

  def Process(self) -> None:
    """Process files with Turbinia."""
    log_file_path = os.path.join(self._output_path, 'turbinia.log')
    self.logger.success('Turbinia log file: {0:s}'.format(log_file_path))

    fspaths = self.state.GetContainers(containers.RemoteFSPath, pop=True)
    hostname = fspaths[0].hostname  # all paths are on the same host

    task_datas = []
    for fspath in fspaths:
      self.logger.info(
          'Processing remote FS path {0:s} from previous collector'.format(
              fspath.path))
      evidence_ = evidence.CompressedDirectory(
          compressed_directory=fspath.path, source_path=fspath.path)
      task_datas.append(self.TurbiniaProcess(evidence_))

    self.logger.info('Files generated by Turbinia:')
    for task_data in task_datas:
      for task in task_data:
        saved_paths = task.get('saved_paths') or []
        for path in saved_paths:
          # Ignore temporary files generated by turbinia
          if path.startswith(turbinia_config.TMP_DIR):
            continue

          # We're only interested in plaso files for the time being.
          if path.endswith('.plaso'):
            self.logger.success('  {0:s}: {1:s}'.format(task['name'], path))
            container = containers.RemoteFSPath(
                path=path, hostname=hostname)
            self.state.StoreContainer(container)


modules_manager.ModulesManager.RegisterModule(TurbiniaArtifactProcessor)
