# -*- coding: utf-8 -*-
"""Processes a directory of artifacts with Turbinia."""

import os
import tempfile

from turbinia import TurbiniaException, evidence
from turbinia import config as turbinia_config

from dftimewolf.lib.containers import containers
from dftimewolf.lib.modules import manager as modules_manager
from dftimewolf.lib.processors.turbinia_gcp import TurbiniaProcessorBase

# pylint: disable=no-member

class TurbiniaArtifactProcessor(TurbiniaProcessorBase):
  """Processes Exported GRR Artifacts with Turbinia.

  Attributes:
    directory_path (str): Name of the directory to process.
  """

  def __init__(self, state, name=None, critical=False):
    """Initializes a Turbinia Artifacts disks processor.

    Args:
      state (DFTimewolfState): recipe state.
      name (Optional[str]): The module's runtime name.
      critical (Optional[bool]): True if the module is critical, which causes
          the entire recipe to fail if the module encounters an error.
    """
    super(TurbiniaArtifactProcessor, self).__init__(
        state, name=name, critical=critical)
    self.directory_path = None

  # pylint: disable=arguments-differ
  def SetUp(self,
            turbinia_config_file,
            project,
            turbinia_zone,
            directory_path,
            sketch_id,
            run_all_jobs):
    """Sets up the object attributes.

    Args:
      turbinia_config_file (str): Full path to the Turbinia config file to use.
      project (str): name of the GCP project containing the disk to process.
      turbinia_zone (str): GCP zone in which the Turbinia server is running.
      directory_path (str): Name of the directory to process.
      sketch_id (int): The Timesketch sketch ID.
      run_all_jobs (bool): Whether to run all jobs instead of a faster subset.
    """
    self.turbinia_config_file = turbinia_config_file
    self.directory_path = directory_path
    if not self.directory_path:
      self.directory_path = tempfile.mkdtemp(prefix='turbinia-results')
      self.logger.info('Turbinia results will be dumped to {0:s}'.format(
          self.directory_path))
    try:
      self.TurbiniaSetUp(project, turbinia_zone, sketch_id, run_all_jobs)
    except TurbiniaException as exception:
      self.ModuleError(str(exception), critical=True)
      return

  def Process(self):
    """Process files with Turbinia."""
    log_file_path = os.path.join(self._output_path, 'turbinia.log')
    self.logger.info('Turbinia log file: {0:s}'.format(log_file_path))

    fspaths = self.state.GetContainers(containers.RemoteFSPath, pop=True)

    task_datas = []
    for fspath in fspaths:
      self.logger.info(
          'Processing remote FS path {0:s} from previous collector'.format(
              fspath.path))
      evidence_ = evidence.CompressedDirectory(
          compressed_directory=fspath.path, local_path=fspath.path)
      task_datas.append(self.TurbiniaProcess(evidence_))

    self.logger.info('Files generated by Turbinia:')
    for task_data in task_datas:
      for task in task_data:
        saved_paths = task.get('saved_paths') or []
        for path in saved_paths:
          # Ignore temporary files generated by turbinia
          if path.startswith(turbinia_config.TMP_PATH):
            continue

          # We're only interested in plaso files for the time being.
          if path.endswith('.plaso'):
            self.logger.info('  {0:s}: {1:s}'.format(task['name'], path))
            container = containers.RemoteFSPath(path=path)
            self.state.StoreContainer(container)


modules_manager.ModulesManager.RegisterModule(TurbiniaArtifactProcessor)
